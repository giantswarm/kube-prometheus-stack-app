apiVersion: batch/v1
kind: Job
metadata:
  name: {{ include "kube-prometheus-stack.crdInstall" . }}
  namespace: {{ .Release.Namespace | quote }}
  annotations:
    # create hook dependencies in the right order
    "helm.sh/hook-weight": "-1"
    {{- include "kube-prometheus-stack.CRDInstallAnnotations" . | nindent 4 }}
  labels:
    app.kubernetes.io/component: {{ include "kube-prometheus-stack.crdInstall" . | quote }}
    {{- include "kube-prometheus-stack.selectorLabels" . | nindent 4 }}
    role: {{ include "kube-prometheus-stack.CRDInstallSelector" . | quote }}
spec:
  template:
    metadata:
      labels:
        app.kubernetes.io/component: {{ include "kube-prometheus-stack.crdInstall" . | quote }}
        {{- include "kube-prometheus-stack.selectorLabels" . | nindent 8 }}
    spec:
      serviceAccountName: {{ include "kube-prometheus-stack.crdInstall" . }}
      securityContext:
        runAsUser: 2000
        runAsGroup: 2000
      tolerations:
      - key: node-role.kubernetes.io/master
        effect: NoSchedule
      containers:
      - name: kubectl
        image: "{{ .Values.image.registry }}/giantswarm/docker-kubectl:latest"
        command:
        - sh
        - -c
        - |
          set -o errexit ; set -o xtrace ; set -o nounset

          # piping stderr to stdout means kubectl's errors are surfaced
          # in the pod's logs.
          exec 2>&1

          namespace=$(kubectl get chart --namespace=giantswarm prometheus-operator-crd --output=jsonpath="{.spec.namespace}")
          kubectl api-resources --api-group=monitoring.coreos.com -oname|tr '\n' ' '|xargs kubectl patch --record=false -p '{"metadata":{"annotations":{"meta.helm.sh/release-name": "prometheus-operator-crd","meta.helm.sh/release-namespace": "'"${namespace}"'"},"labels":{"app.kubernetes.io/managed-by": "Helm"}}}' crd
      restartPolicy: Never
  backoffLimit: 4
